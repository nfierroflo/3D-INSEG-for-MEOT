{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.0+cu117 cuda: True\n",
      "mmdetection: 3.0.0\n",
      "mmcv: 2.0.0\n",
      "mmengine: 0.7.2\n"
     ]
    }
   ],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# adding Folder_2/subfolder to the system path\n",
    "sys.path.insert(0, '/home/nfierroflo/Documents/mmdetection')\n",
    "from inferencia import generate_mask,new_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base\n",
    "from save import *\n",
    "name=\"2024-01-23-18-17-29_0\"\n",
    "redistribute_images(f\"/media/nfierroflo/data/rosbags/{name}/left\",f\"/media/nfierroflo/data/rosbags/{name}/right\",f\"/home/nfierroflo/Documents/stereomatching/RAFT-Stereo/datasets/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: activate: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#generate disparity maps\n",
    "!source activate raftstereo && python demo.py --restore_ckpt models/raftstereo-middlebury.pth \\\n",
    "--corr_implementation alt --mixed_precision \\\n",
    "-l=datasets/2024-01-23-18-17-29_0/*/im0.jpg \\\n",
    "-r=datasets/2024-01-23-18-17-29_0/*/im1.jpg \\\n",
    "--save_numpy\\\n",
    "--output_directory demo_output/2024-01-23-18-17-29_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/763 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/nfierroflo/Documents/mmdetection/checkpoints/mask_rcnn_r50_caffe_fpn_1x_coco_bbox_mAP-0.38__segm_mAP-0.344_20200504_231812-0ebd1859.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/763 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path=\"datasets/2024-01-23-18-17-29_0\"\n",
    "destination_path=f\"demo_output/{name}/inferences\"\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "#iterate over in dataset_path\n",
    "#show all the folders in dataset_path\n",
    "#avoid WARNINGS messages\n",
    "\n",
    "for testF_folder in tqdm(sorted(os.listdir(dataset_path))):\n",
    "    path=dataset_path+\"/\"+testF_folder\n",
    "\n",
    "    generated_mask=generate_mask(path+'/im0.jpg')\n",
    "\n",
    "    indices=torch.where(generated_mask.pred_instances.labels==0)\n",
    "    \n",
    "    masks=generated_mask.pred_instances.masks[indices]\n",
    "    \n",
    "    inf_path=destination_path+\"/\"+testF_folder\n",
    "    \n",
    "    os.makedirs(inf_path, exist_ok=True)\n",
    "\n",
    "    torch.save(masks.cpu(),inf_path+\"/masks.pt\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testF_folder in tqdm(sorted(os.listdir(dataset_path))):\n",
    "    path=dataset_path+\"/\"+testF_folder\n",
    "\n",
    "    masks,scores,labels=new_inference(path+'/im0.jpg')\n",
    "\n",
    "    inf_path=destination_path+\"/\"+testF_folder\n",
    "    \n",
    "    os.makedirs(inf_path, exist_ok=True)\n",
    "\n",
    "    np.save(inf_path+\"/masks.npy\",masks.cpu())\n",
    "    np.save(inf_path+\"/scores.npy\",scores.cpu())\n",
    "    np.save(inf_path+\"/labels.npy\",labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "763it [08:33,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#withoutvelodyne\n",
    "from detectionwithvelodyne import *\n",
    "\n",
    "allPoints=[]\n",
    "time=[]\n",
    "\n",
    "for inference,image in tqdm(zip(sorted(os.listdir(destination_path)),sorted(os.listdir(dataset_path)))):\n",
    "    images_folder_path = Path(dataset_path+\"/\"+image)\n",
    "    inferences_folder_path= Path(destination_path+\"/\"+inference)\n",
    "    disparity_path = Path(f\"demo_output/{name}/{inference}.npy\")\n",
    "    velodynepoints_paths=[]\n",
    "    \n",
    "    save_folder_path=Path(f\"demo_output/{name}/3ddetections/\"+inference)\n",
    "    os.makedirs(save_folder_path, exist_ok=True)\n",
    "    save_path=os.path.join(save_folder_path,\"/pointcloud.html\")\n",
    "    save_path=Path(f\"demo_output/{name}/3ddetections/{inference}/{inference}withcentroids_person1.html\")\n",
    "    try:\n",
    "        fig,P,points_data=visualize_pointcloud(images_folder_path,disparity_path,inferences_folder_path,velodynepoints_paths,save_path,use_velodyne=False,save_html=False,filter_label=True,objects_index=[3])\n",
    "        time.append(float(inference))\n",
    "        allPoints.append(points_data)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one vector for each value T,X,Y,Z\n",
    "T=[]\n",
    "X=[]\n",
    "Y=[]\n",
    "Z=[]\n",
    "for i in range(len(allPoints)):\n",
    "    if allPoints[i]!=[]:\n",
    "        for j in range(len(allPoints[i][0][0])):\n",
    "            T.append(time[i])\n",
    "            X.append(allPoints[i][0][0][j])\n",
    "            Y.append(allPoints[i][0][1][j])\n",
    "            Z.append(allPoints[i][0][2][j])\n",
    "    ##Decide how to deal with 0 detections\n",
    "    else:\n",
    "        T.append(-time[i])\n",
    "        X.append(0)\n",
    "        Y.append(0)\n",
    "        Z.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(T, X, Y, Z)),columns =['T', 'X', 'Y', 'Z'])\n",
    "df.to_csv(f\"demo_output/{name}/person4seq.csv\",index=False,sep=',',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract timestamp from the file name\n",
    "def get_timestamp_from_filename(filename):\n",
    "    return float(filename.split(\"_\")[-1][:-4])\n",
    "\n",
    "# Folder path containing the .npy files for X, Y, and Z\n",
    "velodynepoints_folder = \"/media/nfierroflo/data/rosbags/2024-01-23-18-17-29_0/velodynevelodyne_points/\"\n",
    "\n",
    "# Load all .npy files and store them in lists for X, Y, and Z\n",
    "X_files = [f for f in os.listdir(velodynepoints_folder) if f.startswith(\"X_\")]\n",
    "Y_files = [f for f in os.listdir(velodynepoints_folder) if f.startswith(\"Y_\")]\n",
    "Z_files = [f for f in os.listdir(velodynepoints_folder) if f.startswith(\"Z_\")]\n",
    "\n",
    "# Sort files by timestamp (assuming the timestamps are included in the filenames)\n",
    "X_files.sort(key=get_timestamp_from_filename)\n",
    "Y_files.sort(key=get_timestamp_from_filename)\n",
    "Z_files.sort(key=get_timestamp_from_filename)\n",
    "\n",
    "data = []\n",
    "T=[]\n",
    "X=[]\n",
    "Y=[]\n",
    "Z=[]\n",
    "# Load data and timestamps for each timestamp\n",
    "for X_file, Y_file, Z_file in zip(X_files, Y_files, Z_files):\n",
    "    timestamp = get_timestamp_from_filename(X_file)\n",
    "    X_data = np.load(os.path.join(velodynepoints_folder, X_file)).flatten()\n",
    "    Y_data = np.load(os.path.join(velodynepoints_folder, Y_file)).flatten()\n",
    "    Z_data = np.load(os.path.join(velodynepoints_folder, Z_file)).flatten()\n",
    "    \n",
    "    for x,y,z in zip(X_data,Y_data,Z_data):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        Z.append(z)\n",
    "        print(timestamp)\n",
    "        T.append(timestamp)\n",
    "\n",
    "#create a pandas dataframe\n",
    "df = pd.DataFrame(list(zip(T, X, Y, Z)),columns =['T', 'X', 'Y', 'Z'])\n",
    "print(df.head())\n",
    "df.to_csv(f\"demo_output/{name}/{name}_velodyne_seq.csv\",index=False,sep=',',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
